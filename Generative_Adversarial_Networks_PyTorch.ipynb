{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Generative_Adversarial_Networks_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "5wrV7uqouv46",
        "colab_type": "text"
      },
      "source": [
        "## Setup Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpT-MlR-M16I",
        "colab_type": "code",
        "outputId": "b352cacc-8b78-42fc-c346-0ff5507a1256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "\n",
        "!pip3 install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.4.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "DAsBlsXouv47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import imageio\n",
        "from utils import Logger\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "5py7tSaQuv5J",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "To simplify, the PyTorch MNIST wrapper, which downloads and loads the MNIST dataset. See the [documentation](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) for more information about the interface. The default parameters will take 5,000 of the training examples and place them into a validation dataset. The data will be saved into a folder called `MNIST_data`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "tags": [
          "pdf-ignore"
        ],
        "id": "esOAWRXCuv5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = DataLoader(MNIST('../MNIST_data', \n",
        "                                           download=True,\n",
        "                                           train=True,\n",
        "                                           transform=transforms.Compose([\n",
        "                                                                         transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
        "                                                                         transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
        "                                                                         ])), \n",
        "                                           batch_size=10, \n",
        "                                           shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwgVNkFsuv5P",
        "colab_type": "text"
      },
      "source": [
        "## Random Noise\n",
        "Generate uniform noise from -1 to 1 with shape `[batch_size, dim]`. Implement `sample_noise` Hint: use `torch.rand`. Make sure noise is the correct shape and type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sample_noise_test",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def sample_noise():\n",
        "  return torch.rand(batch_size, dim) + torch.rand(batch_size, dim)*(-1)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExIJoKUtuv5h",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator\n",
        "Our first step is to build a discriminator. Fill in the architecture: A three hidden-layer discriminative neural network.\n",
        " * Fully connected layer \n",
        " * LeakyReLU \n",
        " * Fully connected layer \n",
        " * LeakyReLU \n",
        " * Fully connected layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZFHf7sxuv5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminatorNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()  \n",
        "\n",
        "        input_size = 784 #input value of flattened picture?\n",
        "        output_size = 128  #value of output picture?\n",
        "\n",
        "        self.firstHiddenLayer = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.secondHiddenLayer = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "            \n",
        "        self.outputLayer = nn.Sequential(\n",
        "            nn.Linear(256, output_size), #256 = value of output picture?\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.firstHiddenLayer(x)\n",
        "      x = self.secondHiddenLayer(x)\n",
        "      x = self.outputLayer(x)\n",
        "      return x\n",
        "\n",
        "def images_to_vectors(images):\n",
        "  return images.view(images.size(0), 784)\n",
        "\n",
        "def vectors_to_images(vectors):\n",
        "  return vectors.view(vectors.size(0), 1, 28, 28)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZuso5Ltuv5k",
        "colab_type": "text"
      },
      "source": [
        "# Generator\n",
        "Similar like above:\n",
        " * Fully connected layer\n",
        " * `ReLU`\n",
        " * Fully connected layer\n",
        " * `ReLU`\n",
        " * Fully connected layer\n",
        " * `TanH` (to clip the image to be in the range of [-1,1])\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5SWNf6quv5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 6000 #not sure what the correct value would be, is this how many photos we have?\n",
        "        n_out = 784 #I think 784 is correct? \n",
        "        \n",
        "        #all values will probably have to be replaced, I don't know how to check if this is correct\n",
        "        self.hidden0 = nn.Sequential(\n",
        "            nn.Linear(n_features, 256), \n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(            \n",
        "            nn.Linear(256, 512), \n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024), \n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024, n_out),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "# Noise\n",
        "def noise(size):\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    if torch.cuda.is_available(): return n.cuda() \n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzaT3o-Tuv5v",
        "colab_type": "text"
      },
      "source": [
        "# Optimization\n",
        "Make a function that returns an `optim.Adam` optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6TZIj9y3NtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = DiscriminatorNet()\n",
        "generator = GeneratorNet()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    discriminator.cuda()\n",
        "    generator.cuda()\n",
        "\n",
        "# Optimizers\n",
        "\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "\n",
        "# Loss function\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "# Number of steps to apply to the discriminator\n",
        "d_steps = 1  # In Goodfellow et. al 2014 this variable is assigned to 1\n",
        "# Number of epochs\n",
        "num_epochs = 200\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjAfRT_suv5w",
        "colab_type": "text"
      },
      "source": [
        "# Training a GAN!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "71ZbhmWsuv5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def real_data_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    if torch.cuda.is_available(): return data.cuda()\n",
        "    return data\n",
        "\n",
        "def fake_data_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    if torch.cuda.is_available(): return data.cuda()\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW40rGb74dBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    # Reset gradients\n",
        "   \n",
        "    # Train on Real Data\n",
        "    # Calculate error and backpropagate\n",
        "\n",
        "    # Train on Fake Data\n",
        "    # Calculate error and backpropagate \n",
        "    # Update weights with gradients\n",
        "    \n",
        "    # Return error\n",
        "    # ------------------------------------\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction_real = discriminator(real_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
        "    error_real.backward()\n",
        "\n",
        "    # 1.2 Train on Fake Data\n",
        "    prediction_fake = discriminator(fake_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
        "    error_fake.backward()\n",
        "    \n",
        "    # 1.3 Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error\n",
        "    return error_real + error_fake, prediction_real, prediction_fake\n",
        "\n",
        "# =====================================================================\n",
        "\n",
        "def train_generator(optimizer, fake_data):\n",
        "    # Reset gradients\n",
        "    # Sample noise and generate fake data\n",
        "    # Calculate error and backpropagate\n",
        "    # Update weights with gradients\n",
        "    # Return error\n",
        "    # --------------------------------------\n",
        "\n",
        "    # 2. Train Generator\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
        "    error.backward()\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trsS-BrXERnb",
        "colab_type": "code",
        "outputId": "28cf9a5b-d607-459b-c55b-72a4c5345e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)\n",
        "\n",
        "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "\n",
        "        # Train Discriminator\n",
        "        # Generate fake data\n",
        "        # Train D\n",
        "\n",
        "\n",
        "        # Train Generator\n",
        "        # Generate fake data\n",
        "        # Train G\n",
        "        # Log error\n",
        "\n",
        "        # Model Checkpoints\n",
        "        # ----------------------------\n",
        "\n",
        "        # 1. Train Discriminator\n",
        "        real_data = Variable(images_to_vectors(real_batch))\n",
        "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_data.size(0))).detach()\n",
        "        # Train D\n",
        "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
        "                                                                real_data, \n",
        "                                                                fake_data)\n",
        "\n",
        "        # 2. Train Generator\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_batch.size(0)))\n",
        "        # Train G\n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "        # Log error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "\n",
        "        # Display Progress\n",
        "        if (n_batch) % 100 == 0:\n",
        "            display.clear_output(True)\n",
        "            # Display Images\n",
        "            test_images = vectors_to_images(generator(test_noise)).data.cpu()\n",
        "            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )\n",
        "        # Model Checkpoints\n",
        "        logger.save_models(generator, discriminator, epoch)\n",
        "        logger.save_models(generator, discriminator, epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-831b22997b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Generate fake data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Train D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-3f73522c965f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [10 x 100], m2: [6000 x 256] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
          ]
        }
      ]
    }
  ]
}
